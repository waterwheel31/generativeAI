{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project objective\n",
    "\n",
    "This project is about making a small customization to OpenAI model by adding some data as the context (in the prompt) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open AI setting\n",
    "import openai\n",
    "openAIKey= 'REPLACE_BY_THE_KEY'\n",
    "openai.api_key = openAIKey\n",
    "\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected \"2023_fashion_trends.csv\" for the custom data. This contains information in year 2023 and will add addtional inforamtion to the model considering that training data for gpt3.5 is upto Sep 2021 (as of Jan 2024, https://platform.openai.com/docs/models/gpt-3-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  URL  \\\n",
      "0   https://www.refinery29.com/en-us/fashion-trend...   \n",
      "1   https://www.refinery29.com/en-us/fashion-trend...   \n",
      "2   https://www.refinery29.com/en-us/fashion-trend...   \n",
      "3   https://www.refinery29.com/en-us/fashion-trend...   \n",
      "4   https://www.refinery29.com/en-us/fashion-trend...   \n",
      "..                                                ...   \n",
      "77  https://www.whowhatwear.com/spring-summer-2023...   \n",
      "78  https://www.whowhatwear.com/spring-summer-2023...   \n",
      "79  https://www.whowhatwear.com/spring-summer-2023...   \n",
      "80  https://www.whowhatwear.com/spring-summer-2023...   \n",
      "81  https://www.whowhatwear.com/spring-summer-2023...   \n",
      "\n",
      "                                               Trends  \\\n",
      "0   2023 Fashion Trend: Red. Glossy red hues took ...   \n",
      "1   2023 Fashion Trend: Cargo Pants. Utilitarian w...   \n",
      "2   2023 Fashion Trend: Sheer Clothing. \"Bare it a...   \n",
      "3   2023 Fashion Trend: Denim Reimagined. From dou...   \n",
      "4   2023 Fashion Trend: Shine For The Daytime. The...   \n",
      "..                                                ...   \n",
      "77  If lime green isn't your vibe, rest assured th...   \n",
      "78  \"As someone who can clearly (not fondly) remem...   \n",
      "79  \"Combine this design shift with the fact that ...   \n",
      "80  Thought party season ended at the stroke of mi...   \n",
      "81  \"This season, we saw the revival of the bubble...   \n",
      "\n",
      "                                               Source  \n",
      "0   7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
      "1   7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
      "2   7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
      "3   7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
      "4   7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
      "..                                                ...  \n",
      "77  Spring/Summer 2023 Fashion Trends: 21 Expert-A...  \n",
      "78  Spring/Summer 2023 Fashion Trends: 21 Expert-A...  \n",
      "79  Spring/Summer 2023 Fashion Trends: 21 Expert-A...  \n",
      "80  Spring/Summer 2023 Fashion Trends: 21 Expert-A...  \n",
      "81  Spring/Summer 2023 Fashion Trends: 21 Expert-A...  \n",
      "\n",
      "[82 rows x 3 columns]\n",
      "       magazine                                             Trends  \\\n",
      "0    refinery29  2023 Fashion Trend: Red. Glossy red hues took ...   \n",
      "1    refinery29  2023 Fashion Trend: Cargo Pants. Utilitarian w...   \n",
      "2    refinery29  2023 Fashion Trend: Sheer Clothing. \"Bare it a...   \n",
      "3    refinery29  2023 Fashion Trend: Denim Reimagined. From dou...   \n",
      "4    refinery29  2023 Fashion Trend: Shine For The Daytime. The...   \n",
      "..          ...                                                ...   \n",
      "77  whowhatwear  If lime green isn't your vibe, rest assured th...   \n",
      "78  whowhatwear  \"As someone who can clearly (not fondly) remem...   \n",
      "79  whowhatwear  \"Combine this design shift with the fact that ...   \n",
      "80  whowhatwear  Thought party season ended at the stroke of mi...   \n",
      "81  whowhatwear  \"This season, we saw the revival of the bubble...   \n",
      "\n",
      "                                                 text  \n",
      "0   refinery29:2023 Fashion Trend: Red. Glossy red...  \n",
      "1   refinery29:2023 Fashion Trend: Cargo Pants. Ut...  \n",
      "2   refinery29:2023 Fashion Trend: Sheer Clothing....  \n",
      "3   refinery29:2023 Fashion Trend: Denim Reimagine...  \n",
      "4   refinery29:2023 Fashion Trend: Shine For The D...  \n",
      "..                                                ...  \n",
      "77  whowhatwear:If lime green isn't your vibe, res...  \n",
      "78  whowhatwear:\"As someone who can clearly (not f...  \n",
      "79  whowhatwear:\"Combine this design shift with th...  \n",
      "80  whowhatwear:Thought party season ended at the ...  \n",
      "81  whowhatwear:\"This season, we saw the revival o...  \n",
      "\n",
      "[82 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataPath = './data/2023_fashion_trends.csv'\n",
    "\n",
    "orig_df = pd.read_csv(dataPath)\n",
    "\n",
    "print(orig_df)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['magazine'] = orig_df['URL'].str.extract('www\\.(.*?)\\.com')\n",
    "df['Trends'] = orig_df['Trends']\n",
    "df['text'] = df['magazine'] + \":\" + df['Trends']\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magazine</th>\n",
       "      <th>Trends</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>refinery29</td>\n",
       "      <td>2023 Fashion Trend: Red. Glossy red hues took ...</td>\n",
       "      <td>refinery29:2023 Fashion Trend: Red. Glossy red...</td>\n",
       "      <td>[-0.02681100182235241, -0.030414843931794167, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refinery29</td>\n",
       "      <td>2023 Fashion Trend: Cargo Pants. Utilitarian w...</td>\n",
       "      <td>refinery29:2023 Fashion Trend: Cargo Pants. Ut...</td>\n",
       "      <td>[-0.009645801968872547, -0.03390726447105408, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>refinery29</td>\n",
       "      <td>2023 Fashion Trend: Sheer Clothing. \"Bare it a...</td>\n",
       "      <td>refinery29:2023 Fashion Trend: Sheer Clothing....</td>\n",
       "      <td>[-0.014845591969788074, -0.02283831685781479, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>refinery29</td>\n",
       "      <td>2023 Fashion Trend: Denim Reimagined. From dou...</td>\n",
       "      <td>refinery29:2023 Fashion Trend: Denim Reimagine...</td>\n",
       "      <td>[-0.02278187870979309, -0.01047559641301632, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>refinery29</td>\n",
       "      <td>2023 Fashion Trend: Shine For The Daytime. The...</td>\n",
       "      <td>refinery29:2023 Fashion Trend: Shine For The D...</td>\n",
       "      <td>[-0.0104591129347682, 0.0003251482849009335, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>whowhatwear</td>\n",
       "      <td>If lime green isn't your vibe, rest assured th...</td>\n",
       "      <td>whowhatwear:If lime green isn't your vibe, res...</td>\n",
       "      <td>[-0.0035650806967169046, -0.016749152913689613...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>whowhatwear</td>\n",
       "      <td>\"As someone who can clearly (not fondly) remem...</td>\n",
       "      <td>whowhatwear:\"As someone who can clearly (not f...</td>\n",
       "      <td>[-0.016724731773138046, -0.00880926102399826, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>whowhatwear</td>\n",
       "      <td>\"Combine this design shift with the fact that ...</td>\n",
       "      <td>whowhatwear:\"Combine this design shift with th...</td>\n",
       "      <td>[-0.021235937252640724, -0.025398779660463333,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>whowhatwear</td>\n",
       "      <td>Thought party season ended at the stroke of mi...</td>\n",
       "      <td>whowhatwear:Thought party season ended at the ...</td>\n",
       "      <td>[-0.021053023636341095, -0.019290756434202194,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>whowhatwear</td>\n",
       "      <td>\"This season, we saw the revival of the bubble...</td>\n",
       "      <td>whowhatwear:\"This season, we saw the revival o...</td>\n",
       "      <td>[-0.032466307282447815, 0.001880919560790062, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       magazine                                             Trends  \\\n",
       "0    refinery29  2023 Fashion Trend: Red. Glossy red hues took ...   \n",
       "1    refinery29  2023 Fashion Trend: Cargo Pants. Utilitarian w...   \n",
       "2    refinery29  2023 Fashion Trend: Sheer Clothing. \"Bare it a...   \n",
       "3    refinery29  2023 Fashion Trend: Denim Reimagined. From dou...   \n",
       "4    refinery29  2023 Fashion Trend: Shine For The Daytime. The...   \n",
       "..          ...                                                ...   \n",
       "77  whowhatwear  If lime green isn't your vibe, rest assured th...   \n",
       "78  whowhatwear  \"As someone who can clearly (not fondly) remem...   \n",
       "79  whowhatwear  \"Combine this design shift with the fact that ...   \n",
       "80  whowhatwear  Thought party season ended at the stroke of mi...   \n",
       "81  whowhatwear  \"This season, we saw the revival of the bubble...   \n",
       "\n",
       "                                                 text  \\\n",
       "0   refinery29:2023 Fashion Trend: Red. Glossy red...   \n",
       "1   refinery29:2023 Fashion Trend: Cargo Pants. Ut...   \n",
       "2   refinery29:2023 Fashion Trend: Sheer Clothing....   \n",
       "3   refinery29:2023 Fashion Trend: Denim Reimagine...   \n",
       "4   refinery29:2023 Fashion Trend: Shine For The D...   \n",
       "..                                                ...   \n",
       "77  whowhatwear:If lime green isn't your vibe, res...   \n",
       "78  whowhatwear:\"As someone who can clearly (not f...   \n",
       "79  whowhatwear:\"Combine this design shift with th...   \n",
       "80  whowhatwear:Thought party season ended at the ...   \n",
       "81  whowhatwear:\"This season, we saw the revival o...   \n",
       "\n",
       "                                           embeddings  \n",
       "0   [-0.02681100182235241, -0.030414843931794167, ...  \n",
       "1   [-0.009645801968872547, -0.03390726447105408, ...  \n",
       "2   [-0.014845591969788074, -0.02283831685781479, ...  \n",
       "3   [-0.02278187870979309, -0.01047559641301632, 0...  \n",
       "4   [-0.0104591129347682, 0.0003251482849009335, 0...  \n",
       "..                                                ...  \n",
       "77  [-0.0035650806967169046, -0.016749152913689613...  \n",
       "78  [-0.016724731773138046, -0.00880926102399826, ...  \n",
       "79  [-0.021235937252640724, -0.025398779660463333,...  \n",
       "80  [-0.021053023636341095, -0.019290756434202194,...  \n",
       "81  [-0.032466307282447815, 0.001880919560790062, ...  \n",
       "\n",
       "[82 rows x 4 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Send text data to OpenAI model to get embeddings\n",
    "\n",
    "    inputText = df.iloc[i:i+batch_size][\"text\"]\n",
    "\n",
    "    response = openai.Embedding.create(\n",
    "        input=inputText.tolist(),\n",
    "        engine=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    # Add embeddings to list\n",
    "    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "# Add embeddings list to dataframe\n",
    "df[\"embeddings\"] = embeddings\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "\n",
    "def get_rows_sorted_by_relevance(question, df):\n",
    "\n",
    "    EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "    \n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "    \n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt\n",
    "\n",
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "\n",
    "\n",
    "def create_prompt(question, df, max_token_count, withData=True):\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below\n",
    "\n",
    "Context:\n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + len(tokenizer.encode(question))\n",
    "\n",
    "    context = []\n",
    "    if withData:\n",
    "        for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "            text_token_count = len(tokenizer.encode(text))\n",
    "            current_token_count += text_token_count\n",
    "\n",
    "            if current_token_count <= max_token_count:\n",
    "                context.append(text)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create answer \n",
    "\n",
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "def answer_question(\n",
    "    question, df, max_prompt_tokens=1800, max_answer_tokens=300, withData=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "    \n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = create_prompt(question, df, max_prompt_tokens, withData)\n",
    "   \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print('error')\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, it is not possible to accurately answer the question as the context does not provide any information about fashion trends in 2023.\n"
     ]
    }
   ],
   "source": [
    "# basic answer\n",
    "\n",
    "question1 = \"what are the fashion trends in 2023?\"\n",
    "withCustomData = False\n",
    "\n",
    "print(answer_question(question1, df, 2000, 1000, withData=withCustomData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sheer clothing\n",
      "2. Daytime shine\n",
      "3. Reds\n",
      "4. Cargo pants\n",
      "5. Denim reimagined\n",
      "6. Indie sleaze\n",
      "7. Perfectly cut trousers\n",
      "8. Simplicity and everyday dressing\n",
      "9. Cobalt Blue\n",
      "10. Maxi skirts\n",
      "11. Pinstripe tailoring\n",
      "12. The tailored look.\n"
     ]
    }
   ],
   "source": [
    "# custom answer\n",
    "withCustomData = True\n",
    "\n",
    "print(answer_question(question1, df, 2000, 1000, withData=withCustomData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, I do not have any examples as I am a language AI and do not have access to current or future fashion trends. I suggest consulting fashion magazines like Glamour and Vogue for more information on the different descriptions for fashion trends in 2023.\n"
     ]
    }
   ],
   "source": [
    "# basic answer\n",
    "\n",
    "question2 = \"how the descriptions for the fashion trends in 2023 are different between Glamour and Vogue? Please highlight the examples mentioned by each. If you do not have any examples, please tell so\"\n",
    "withCustomData = False\n",
    "\n",
    "print(answer_question(question2, df, 2000, 1000, withData=withCustomData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glamour's description of the 2023 fashion trends focuses on a specific decade, the '90s, with their mention of \"dopamine-dressing\" and \"Phoebe Philo.\" They also highlight the trend of subdued looks and wardrobe essentials such as tailored blazers, formfitting tees, and loose trousers.\n",
      "\n",
      "Vogue, on the other hand, offers a more diverse range of trends, such as the modern boho trend seen on the runways of Jil Sander, Marni, Prada, and Dries van Noten. They also mention the trend of detailed denim, using Altuzarra's maxi skirt as an example. Additionally, they mention a \"liquid silver\" trend, as well as a focus on shine for daytime wear.\n"
     ]
    }
   ],
   "source": [
    "# custom answer\n",
    "withCustomData = True\n",
    "\n",
    "print(answer_question(question2, df, 2000, 1000, withData=withCustomData))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
